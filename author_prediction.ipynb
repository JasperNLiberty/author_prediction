{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is build a classifier that predicts the author of a given book. Here are a few key steps in making the classifier.\n",
    "\n",
    "1. Read in all novels (6 in total), identify the most frequently used words as top_words_set\n",
    "2. Read in a novel, break it up into chunks of the same length\n",
    "3. For each chunk, count the frequencies of words that belong to top_words_set\n",
    "4. Create a data frame, each row corresponds to a chunk, the features are the counts, label with author_id\n",
    "5. Perform 2-4 for each novel, and stack up the data frames into one data frame that contains all novels (6 in total)\n",
    "6. create train and test set from the data frame\n",
    "7. use a classifer (Random Forest chosen) to learn the train set and calculate accuracy score\n",
    "8. read in a new novel (different from 6 novels above) and convert it to a data frame using the same frequency counting technique\n",
    "9. predict the author of the new novel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions that create the features (word-frequency count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global top_num, chunk_size\n",
    "top_num = 200\n",
    "chunk_size = 2000\n",
    "\n",
    "\n",
    "def find_top_words_freq(words_stream, top_words_set):\n",
    "    stream_freq = dict([(top_word,0) for top_word in top_words_set])\n",
    "    for word in words_stream:\n",
    "        if word in top_words_set:\n",
    "            stream_freq[word] += 1\n",
    "    return stream_freq\n",
    "\n",
    "def define_top_words_set(novel):\n",
    "    total_num_words = len(novel)\n",
    "    \n",
    "    word_freq = {}\n",
    "    words = re.split('\\W+', novel)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in word_freq:\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1\n",
    "\n",
    "    word_freq_list = [pair for pair in word_freq.iteritems()]\n",
    "    word_freq_list_sorted = sorted(word_freq_list ,key=lambda x:-x[1])\n",
    "    word_freq_list_top = word_freq_list_sorted[:top_num]\n",
    "    top_words_set = set(dict(word_freq_list_top).keys())\n",
    "    \n",
    "    return top_words_set\n",
    "\n",
    "def create_freq(novel, top_words_set):\n",
    "    \n",
    "    words = re.split('\\W+', novel)\n",
    "    words_collection = [words[i:i+chunk_size] for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "    freq_dfs = [pd.DataFrame(find_top_words_freq(collection, top_words_set), index = ['0']) for collection in words_collection]\n",
    "    freq = pd.concat(freq_dfs).reset_index().drop('index',axis=1)\n",
    "\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create feature data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./author_id/DavidHerbertLawrence_SonsandLovers.txt') as f:\n",
    "    novel1 = f.read()\n",
    "    \n",
    "with open('./author_id/GeorgeMacDonald_AttheBackoftheNorthWind.txt') as f:\n",
    "    novel2 = f.read()\n",
    "    \n",
    "with open('./author_id/HenryJames_TheAspernPapers.txt') as f:\n",
    "    novel3 = f.read()\n",
    "    \n",
    "with open('./author_id/JosephConrad_HeartofDarkness.txt') as f:\n",
    "    novel4 = f.read()\n",
    "\n",
    "with open('./author_id/LewisCarroll_ThroughtheLooking-Glass.txt') as f:\n",
    "    novel5 = f.read()\n",
    "    \n",
    "with open('./author_id/MarkTwain_AdventuresofHuckleberryFinn.txt') as f:\n",
    "    novel6 = f.read()\n",
    "    \n",
    "\n",
    "top_words_set1 = define_top_words_set(novel1)\n",
    "top_words_set2 = define_top_words_set(novel2)\n",
    "top_words_set3 = define_top_words_set(novel3)\n",
    "top_words_set4 = define_top_words_set(novel4)\n",
    "top_words_set5 = define_top_words_set(novel5)\n",
    "top_words_set6 = define_top_words_set(novel6)\n",
    "top_words_set_all = set.intersection(top_words_set1, top_words_set2, top_words_set3, top_words_set4, top_words_set5, top_words_set6)\n",
    "top_words_set = top_words_set_all\n",
    "\n",
    "freq1 = create_freq(novel1, top_words_set)\n",
    "freq1['author_id'] = 1\n",
    "\n",
    "\n",
    "freq2 = create_freq(novel2, top_words_set)\n",
    "freq2['author_id'] = 2\n",
    "freq2.head()\n",
    "\n",
    "\n",
    "freq3 = create_freq(novel3, top_words_set)\n",
    "freq3['author_id'] = 3\n",
    "freq3.head()\n",
    "\n",
    "\n",
    "freq4 = create_freq(novel4, top_words_set)\n",
    "freq4['author_id'] = 4\n",
    "freq4.head()\n",
    "\n",
    "\n",
    "freq5 = create_freq(novel5, top_words_set)\n",
    "freq5['author_id'] = 5\n",
    "freq5.head()\n",
    "\n",
    "\n",
    "freq6 = create_freq(novel6, top_words_set)\n",
    "freq6['author_id'] = 6\n",
    "freq6.head()\n",
    "\n",
    "author_dict = {1:'David Herbert Lawrence', 2:'George MacDonald', 3:'Henry James', 4:'Joseph Conrad', 5:'Lewis Carroll', 6:'Mark Twain'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_all = pd.concat([freq1,freq2,freq3,freq4,freq5,freq6])\n",
    "\n",
    "freq_all.reset_index().drop('index', axis=1)\n",
    "\n",
    "df_train = pd.concat([train_test_split(freqX, test_size=0.3, random_state=42)[0] for freqX in [freq1,freq2,freq3,freq4,freq5,freq6]])\n",
    "\n",
    "df_test = pd.concat([train_test_split(freqX, test_size=0.3, random_state=42)[1] for freqX in [freq1,freq2,freq3,freq4,freq5,freq6]])\n",
    "\n",
    "X_train = np.array(df_train.iloc[:, 0:len(top_words_set)])\n",
    "\n",
    "X_test = np.array(df_test.iloc[:, 0:len(top_words_set)])\n",
    "\n",
    "y_train = np.array(df_train.iloc[:, len(top_words_set)])\n",
    "\n",
    "y_test = np.array(df_test.iloc[:, len(top_words_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93243243243243246"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=500)\n",
    "rfc.fit(X_train, y_train)\n",
    "accuracy_score(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Henry James'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./author_id/HenryJames_TheTurnoftheScrew.txt') as f:\n",
    "    novelTest = f.read()\n",
    "freqTest = create_freq(novelTest, top_words_set)\n",
    "\n",
    "author_dict[mode(rfc.predict(freqTest))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Twain'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./author_id/MarkTwain_TheAdventuresofTomSawyer.txt') as f:\n",
    "    novelTest = f.read()\n",
    "freqTest = create_freq(novelTest, top_words_set)\n",
    "\n",
    "author_dict[mode(rfc.predict(freqTest))[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier has a reasonable accuracy score given its simplicity. More importantly, it worked on other novels(not used in training at all) by the same writer, indicating the style of writing is similar for one writer.\n",
    "\n",
    "With more time, chunk_size and number of top words could potentially improve the accurarcy score. More advanced features such as N-grams should help as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
